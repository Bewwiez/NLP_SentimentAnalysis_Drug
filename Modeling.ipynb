{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07406620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy as np \n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer, EvalPrediction\n",
    "#imports all of the libraries needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ab3aba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using GPU: NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"PyTorch is using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"PyTorch is using CPU\")\n",
    "#sanity check on what my computer is using. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7b6b0",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57647360",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_Path = 'drugLibTrain_raw.tsv'\n",
    "test_file_Path = 'drugLibTest_raw.tsv'\n",
    "drug_train_df = pd.read_csv(train_file_Path, sep = '\\t')\n",
    "drug_test_df = pd.read_csv(test_file_Path,sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b03c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_train_df['benefitsReview'] = drug_train_df['benefitsReview'].fillna('')\n",
    "drug_test_df['benefitsReview'] = drug_test_df['benefitsReview'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e454339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings from the data is from 1-10, i'm just changing them into sentiments of positive(2) negative(0) and neutral(1)\n",
    "def turn_to_sentiment(ratings):\n",
    "    if ratings >= 8:\n",
    "        return 2\n",
    "    elif ratings <= 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9fec6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_train_df['sentiment_label'] = drug_train_df['rating'].apply(turn_to_sentiment)\n",
    "drug_test_df['sentiment_label'] = drug_test_df['rating'].apply(turn_to_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b5755",
   "metadata": {},
   "source": [
    "## Paths for things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d7c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Path = 'dmis-lab/biobert-v1.1' \n",
    "finetune_output = \"./sentiment_finetuning_cv\"\n",
    "final_model_output = \"./final_sentiment_model\"\n",
    "label_column = 'sentiment'\n",
    "num_unique_Labels = 3\n",
    "labels = ['negative','neutral','positive']\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "# update the reviews (side effect or benefits)\n",
    "type_review = 'benefitsReview'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4095709",
   "metadata": {},
   "source": [
    "## Functions for modeling and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e03801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43338f4435f4f7295088e31b3d43f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ling Ling Li\\.cache\\huggingface\\hub\\models--dmis-lab--biobert-v1.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a21e260f23b429097f1ed6e60d5ed42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/462 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e34acd0ac9045938368fe1fefaa8d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fc9d282f1748129334d520ee45cfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_Path)\n",
    "def get_model(): \n",
    "    model= AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_Path,\n",
    "        num_labels = num_unique_Labels,\n",
    "        id2label = id2label,\n",
    "        label2id =label2id\n",
    "    )\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(review):\n",
    "    list_form = review.tolist() #turns my column into a list form\n",
    "    return tokenizer(\n",
    "    list_form,\n",
    "    max_length=256, #this value can be changed. I'm only using half of 512 so my simulation doesnt take longer\n",
    "    truncation=True,             \n",
    "    padding=\"max_length\",        \n",
    "    return_tensors=\"pt\"         \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578e4e9",
   "metadata": {},
   "source": [
    "### Training Arguments Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these values can be adjusted if there is time to run more CV loops for better understanding such as more epochs changing Learning rate etc\n",
    "LR = 2e-5\n",
    "epoch_Numb = 2\n",
    "batch_size = 16\n",
    "\n",
    "training_Args = TrainingArguments(\n",
    "output_dir=finetune_output,\n",
    "num_train_epochs=epoch_Numb,\n",
    "learning_rate=LR,\n",
    "per_device_train_batch_size=batch_size,\n",
    "per_device_eval_batch_size=batch_size,\n",
    "warmup_steps=100,\n",
    "weight_decay=0.01,\n",
    "logging_steps=50,\n",
    "eval_strategy=\"epoch\",\n",
    "save_strategy=\"epoch\",\n",
    "load_best_model_at_end=True,\n",
    "metric_for_best_model=\"f1_weighted\",\n",
    "save_total_limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972d460",
   "metadata": {},
   "source": [
    "### Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_metrics(eval_pred: EvalPrediction):\n",
    "    predictions, label_ids = eval_pred\n",
    "    predicted_ids = np.argmax(predictions, axis=-1)\n",
    "    accuracy = accuracy_score(y_true=label_ids, y_pred=predicted_ids)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support( #relying on sklearn for calculating the metrics\n",
    "        y_true=label_ids, y_pred=predicted_ids, average='weighted', zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1,\n",
    "        'precision_weighted': precision,\n",
    "        'recall_weighted': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71bd3e",
   "metadata": {},
   "source": [
    "##### just testing the above function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b196c3",
   "metadata": {},
   "source": [
    "##### HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_Benefits = tokenize(drug_train_df['benefitsReview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e9f088",
   "metadata": {},
   "source": [
    "### HF Training Benefits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b28d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these will be used after the CV\n",
    "drug_train_df_sentiment_Label = drug_train_df['sentiment_label']\n",
    "review_train_Dict = {\"input_ids\" : tokenized_Benefits['input_ids'], \"token_type_ids\": tokenized_Benefits['token_type_ids'],\"attention_mask\": tokenized_Benefits['attention_mask'], \"labels\": torch.tensor(drug_train_df_sentiment_Label)}\n",
    "review_train_dataset = Dataset.from_dict(review_train_Dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e8a01",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9145c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5 \n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "all_fold_metrics = []\n",
    "y_split_labels = drug_train_df_sentiment_Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b43c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_train_benefits_df = drug_train_df[['benefitsReview','sentiment_label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2594cc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Starting Fold 1/5 =====\n",
      "Tokenizing training data for fold 1...\n",
      "Tokenizing validation data for fold 1...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 23\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#turning my tokenized data into hugging face datasets\u001b[39;00m\n\u001b[0;32m     16\u001b[0m train_data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenized_train_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenized_train_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenized_train_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: train_labels_fold\n\u001b[0;32m     21\u001b[0m }\n\u001b[1;32m---> 23\u001b[0m train_dataset_fold \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(train_data_dict)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#turning my tokenized data into hugging face datasets\u001b[39;00m\n\u001b[0;32m     26\u001b[0m val_data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenized_val_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenized_val_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenized_val_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: val_labels_fold\n\u001b[0;32m     31\u001b[0m }\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\arrow_dataset.py:953\u001b[0m, in \u001b[0;36mDataset.from_dict\u001b[1;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    945\u001b[0m     info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m Features(\n\u001b[0;32m    946\u001b[0m         {\n\u001b[0;32m    947\u001b[0m             col: generate_from_arrow_type(data\u001b[38;5;241m.\u001b[39mtype)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    951\u001b[0m         }\n\u001b[0;32m    952\u001b[0m     )\n\u001b[1;32m--> 953\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(pa_table, info\u001b[38;5;241m=\u001b[39minfo, split\u001b[38;5;241m=\u001b[39msplit)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\arrow_dataset.py:682\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, arrow_table, info, split, indices_table, fingerprint)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;66;03m# Infer fingerprint if None\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fingerprint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fingerprint \u001b[38;5;241m=\u001b[39m generate_fingerprint(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;66;03m# Sanity checks\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\fingerprint.py:216\u001b[0m, in \u001b[0;36mgenerate_fingerprint\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(key)\n\u001b[1;32m--> 216\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(state[key])\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# hash data files last modification timestamps as well\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cache_file \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mcache_files:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\fingerprint.py:192\u001b[0m, in \u001b[0;36mHasher.update\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     header_for_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 192\u001b[0m     value_for_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhash(value)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mupdate(header_for_update\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mupdate(value_for_update\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\fingerprint.py:188\u001b[0m, in \u001b[0;36mHasher.hash\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhash\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mhash_bytes(dumps(value))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:109\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Pickle an object to a string.\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m file \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[1;32m--> 109\u001b[0m dump(obj, file)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:103\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file):\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pickle an object to a file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     Pickler(file, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdump(obj)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:420\u001b[0m, in \u001b[0;36mPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     logger\u001b[38;5;241m.\u001b[39mtrace_setup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 420\u001b[0m     StockPickler\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;28mself\u001b[39m, obj)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:484\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mstart_framing()\n\u001b[1;32m--> 484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(obj)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(STOP)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mend_framing()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:600\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(obj\u001b[38;5;241m=\u001b[39mobj, \u001b[38;5;241m*\u001b[39mrv)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:714\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_setter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 714\u001b[0m         save(state)\n\u001b[0;32m    715\u001b[0m         write(BUILD)\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;66;03m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;66;03m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:1217\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dill(pickler, child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m pickler\u001b[38;5;241m.\u001b[39m_session:\n\u001b[0;32m   1215\u001b[0m         \u001b[38;5;66;03m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m         pickler\u001b[38;5;241m.\u001b[39m_first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m     StockPickler\u001b[38;5;241m.\u001b[39msave_dict(pickler, obj)\n\u001b[0;32m   1218\u001b[0m     logger\u001b[38;5;241m.\u001b[39mtrace(pickler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# D2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:989\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m DICT)\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 989\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_setitems(obj\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:83\u001b[0m, in \u001b[0;36mPickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfingerprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hasher\n\u001b[0;32m     82\u001b[0m     items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(items, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Hasher\u001b[38;5;241m.\u001b[39mhash(x[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m---> 83\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39m_batch_setitems(\u001b[38;5;28mself\u001b[39m, items)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:1013\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[0;32m   1012\u001b[0m         save(k)\n\u001b[1;32m-> 1013\u001b[0m         save(v)\n\u001b[0;32m   1014\u001b[0m     write(SETITEMS)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:600\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(obj\u001b[38;5;241m=\u001b[39mobj, \u001b[38;5;241m*\u001b[39mrv)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:689\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m     save(func)\n\u001b[1;32m--> 689\u001b[0m     save(args)\n\u001b[0;32m    690\u001b[0m     write(REDUCE)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;66;03m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:904\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m--> 904\u001b[0m         save(element)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:949\u001b[0m, in \u001b[0;36m_Pickler.save_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m LIST)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_appends(obj)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:973\u001b[0m, in \u001b[0;36m_Pickler._batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    971\u001b[0m     write(MARK)\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[1;32m--> 973\u001b[0m         save(x)\n\u001b[0;32m    974\u001b[0m     write(APPENDS)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:600\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(obj\u001b[38;5;241m=\u001b[39mobj, \u001b[38;5;241m*\u001b[39mrv)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:689\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m     save(func)\n\u001b[1;32m--> 689\u001b[0m     save(args)\n\u001b[0;32m    690\u001b[0m     write(REDUCE)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;66;03m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:904\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m--> 904\u001b[0m         save(element)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:949\u001b[0m, in \u001b[0;36m_Pickler.save_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m LIST)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_appends(obj)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:976\u001b[0m, in \u001b[0;36m_Pickler._batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    974\u001b[0m     write(APPENDS)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n\u001b[1;32m--> 976\u001b[0m     save(tmp[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    977\u001b[0m     write(APPEND)\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# else tmp is empty, and we're done\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:600\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(obj\u001b[38;5;241m=\u001b[39mobj, \u001b[38;5;241m*\u001b[39mrv)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:689\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m     save(func)\n\u001b[1;32m--> 689\u001b[0m     save(args)\n\u001b[0;32m    690\u001b[0m     write(REDUCE)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;66;03m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:904\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m--> 904\u001b[0m         save(element)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:919\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    917\u001b[0m write(MARK)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m--> 919\u001b[0m     save(element)\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;66;03m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;66;03m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;66;03m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;66;03m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[0;32m    929\u001b[0m     get \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(memo[\u001b[38;5;28mid\u001b[39m(obj)][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:949\u001b[0m, in \u001b[0;36m_Pickler.save_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m LIST)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_appends(obj)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:976\u001b[0m, in \u001b[0;36m_Pickler._batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    974\u001b[0m     write(APPENDS)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n\u001b[1;32m--> 976\u001b[0m     save(tmp[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    977\u001b[0m     write(APPEND)\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# else tmp is empty, and we're done\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:919\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    917\u001b[0m write(MARK)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m--> 919\u001b[0m     save(element)\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;66;03m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;66;03m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;66;03m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;66;03m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[0;32m    929\u001b[0m     get \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(memo[\u001b[38;5;28mid\u001b[39m(obj)][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:949\u001b[0m, in \u001b[0;36m_Pickler.save_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m LIST)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_appends(obj)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:973\u001b[0m, in \u001b[0;36m_Pickler._batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    971\u001b[0m     write(MARK)\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[1;32m--> 973\u001b[0m         save(x)\n\u001b[0;32m    974\u001b[0m     write(APPENDS)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:600\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(obj\u001b[38;5;241m=\u001b[39mobj, \u001b[38;5;241m*\u001b[39mrv)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:689\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m     save(func)\n\u001b[1;32m--> 689\u001b[0m     save(args)\n\u001b[0;32m    690\u001b[0m     write(REDUCE)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;66;03m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:904\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m--> 904\u001b[0m         save(element)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:827\u001b[0m, in \u001b[0;36m_Pickler.save_bytearray\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(\u001b[38;5;28mbytearray\u001b[39m, (), obj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(\u001b[38;5;28mbytearray\u001b[39m, (\u001b[38;5;28mbytes\u001b[39m(obj),), obj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_bytearray_no_memo(obj)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:689\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m     save(func)\n\u001b[1;32m--> 689\u001b[0m     save(args)\n\u001b[0;32m    690\u001b[0m     write(REDUCE)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;66;03m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:904\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m--> 904\u001b[0m         save(element)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\datasets\\utils\\_dill.py:70\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[0;32m     69\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torchdynamo_orig_callable\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj)\n\u001b[1;32m---> 70\u001b[0m dill\u001b[38;5;241m.\u001b[39mPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id\u001b[38;5;241m=\u001b[39msave_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m StockPickler\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m, obj, save_persistent_id)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:557\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    555\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     f(\u001b[38;5;28mself\u001b[39m, obj)  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:808\u001b[0m, in \u001b[0;36m_Pickler.save_bytes\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(codecs\u001b[38;5;241m.\u001b[39mencode,\n\u001b[0;32m    806\u001b[0m                          (\u001b[38;5;28mstr\u001b[39m(obj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m), obj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_bytes_no_memo(obj)\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:796\u001b[0m, in \u001b[0;36m_Pickler._save_bytes_no_memo\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_large_bytes(BINBYTES8 \u001b[38;5;241m+\u001b[39m pack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Q\u001b[39m\u001b[38;5;124m\"\u001b[39m, n), obj)\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39m_FRAME_SIZE_TARGET:\n\u001b[1;32m--> 796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_large_bytes(BINBYTES \u001b[38;5;241m+\u001b[39m pack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, n), obj)\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(BINBYTES \u001b[38;5;241m+\u001b[39m pack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, n) \u001b[38;5;241m+\u001b[39m obj)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:245\u001b[0m, in \u001b[0;36m_Framer.write_large_bytes\u001b[1;34m(self, header, payload)\u001b[0m\n\u001b[0;32m    242\u001b[0m write \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_write\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_frame:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# Terminate the current frame and flush it to the file.\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit_frame(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Perform direct write of the header and payload of the large binary\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# object. Be careful not to concatenate the header and the payload\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# prior to calling 'write' as we do not want to allocate a large\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# temporary bytes object.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# We intentionally do not insert a protocol 4 frame opcode to make\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# it possible to optimize file.read calls in the loader.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m write(header)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\pickle.py:227\u001b[0m, in \u001b[0;36m_Framer.commit_frame\u001b[1;34m(self, force)\u001b[0m\n\u001b[0;32m    222\u001b[0m     write(FRAME \u001b[38;5;241m+\u001b[39m pack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Q\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data)))\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Issue a separate call to write to append the frame\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# contents without concatenation to the above to avoid a\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# memory copy.\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m write(data)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Start the new frame with a new io.BytesIO instance so that\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# the file object can have delayed access to the previous frame\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# contents via an unreleased memoryview of the previous\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# io.BytesIO instance.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_frame \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold_num, (train_idx, val_idx) in enumerate(skf.split(drug_train_benefits_df['benefitsReview'], y_split_labels)):\n",
    "    print(f\"\\n===== Starting Fold {fold_num + 1}/{N_SPLITS} =====\")\n",
    "    df_train_fold = drug_train_benefits_df.iloc[train_idx]\n",
    "    df_val_fold = drug_train_benefits_df.iloc[val_idx]\n",
    "    #tokenize the reviews\n",
    "    print(f\"Tokenizing training data for fold {fold_num + 1}...\")\n",
    "    tokenized_train_inputs = tokenize(df_train_fold['benefitsReview'])\n",
    "    print(f\"Tokenizing validation data for fold {fold_num + 1}...\")\n",
    "    tokenized_val_inputs = tokenize(df_val_fold['benefitsReview'])\n",
    "\n",
    "    #labels\n",
    "    train_labels_fold = torch.tensor(df_train_fold['sentiment_label'].tolist())\n",
    "    val_labels_fold = torch.tensor(df_val_fold['sentiment_label'].tolist())\n",
    "\n",
    "    #turning my tokenized data into hugging face datasets\n",
    "    train_data_dict = {\n",
    "        'input_ids': tokenized_train_inputs['input_ids'],\n",
    "        'attention_mask': tokenized_train_inputs['attention_mask'],\n",
    "        'token_type_ids': tokenized_train_inputs['token_type_ids'],\n",
    "        'labels': train_labels_fold\n",
    "    }\n",
    "\n",
    "    train_dataset_fold = Dataset.from_dict(train_data_dict)\n",
    "    \n",
    "    #turning my tokenized data into hugging face datasets\n",
    "    val_data_dict = {\n",
    "        'input_ids': tokenized_val_inputs['input_ids'],\n",
    "        'attention_mask': tokenized_val_inputs['attention_mask'],\n",
    "        'token_type_ids': tokenized_val_inputs['token_type_ids'],\n",
    "        'labels': val_labels_fold\n",
    "    }\n",
    "    \n",
    "    eval_dataset_fold = Dataset.from_dict(val_data_dict)\n",
    "\n",
    "    print(f\"Fold {fold_num + 1}: Train dataset size: {len(train_dataset_fold)}, Eval dataset size: {len(eval_dataset_fold)}\")\n",
    "\n",
    "    model_fold = get_model()\n",
    "\n",
    "    fold_output_dir = f\"{finetune_output}/fold_{fold_num + 1}\"\n",
    "\n",
    "    trainer_fold = Trainer(\n",
    "        model=model_fold,\n",
    "        args=training_Args, # Use the args specified from the training arguments cell\n",
    "        train_dataset=train_dataset_fold,\n",
    "        eval_dataset=eval_dataset_fold,\n",
    "        compute_metrics=compute_classification_metrics,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    print(f\"Training fold {fold_num + 1}...\") \n",
    "    trainer_fold.train() \n",
    "\n",
    "    print(f\"Evaluating fold {fold_num + 1}...\") \n",
    "    metrics = trainer_fold.evaluate() \n",
    "\n",
    "    all_fold_metrics.append(metrics) \n",
    "    print(f\"Metrics for Fold {fold_num + 1}: {metrics}\") \n",
    "\n",
    "    print(\"\\n===== Cross-Validation Results Summary =====\")\n",
    "\n",
    "if all_fold_metrics: \n",
    "    f1_weighted_key = 'eval_f1_weighted'\n",
    "    f1_macro_key = 'eval_f1_macro' \n",
    "    accuracy_key = 'eval_accuracy'\n",
    "    precision_weighted_key = 'eval_precision_weighted'\n",
    "    recall_weighted_key = 'eval_recall_weighted'\n",
    "\n",
    "    # Check if the primary key for F1 exists, to avoid errors if a fold failed or metrics changed\n",
    "    if not all_fold_metrics[0] or f1_weighted_key not in all_fold_metrics[0]:\n",
    "        print(f\"Warning: Key '{f1_weighted_key}' not found in the first fold's metrics.\")\n",
    "        print(f\"Available keys in first fold: {all_fold_metrics[0].keys() if all_fold_metrics[0] else 'N/A'}\")\n",
    "        #fail safe\n",
    "        potential_f1_keys = [k for k in (all_fold_metrics[0] or {}).keys() if 'f1_weighted' in k]\n",
    "        if potential_f1_keys:\n",
    "            f1_weighted_key = potential_f1_keys[0]\n",
    "            print(f\"Using alternative key for F1 weighted: '{f1_weighted_key}'\")\n",
    "        else:\n",
    "            f1_weighted_key = None # Cannot calculate average F1 weighted\n",
    "\n",
    "    if f1_weighted_key:\n",
    "        avg_f1_weighted = np.mean([m.get(f1_weighted_key, 0) for m in all_fold_metrics])\n",
    "        print(f\"Average {f1_weighted_key} across {N_SPLITS} folds: {avg_f1_weighted:.4f}\")\n",
    "\n",
    "\n",
    "    avg_accuracy = np.mean([m.get(accuracy_key, 0) for m in all_fold_metrics])\n",
    "    print(f\"Average {accuracy_key} across {N_SPLITS} folds: {avg_accuracy:.4f}\")\n",
    "\n",
    "    avg_precision_weighted = np.mean([m.get(precision_weighted_key, 0) for m in all_fold_metrics])\n",
    "    print(f\"Average {precision_weighted_key} across {N_SPLITS} folds: {avg_precision_weighted:.4f}\")\n",
    "\n",
    "    avg_recall_weighted = np.mean([m.get(recall_weighted_key, 0) for m in all_fold_metrics])\n",
    "    print(f\"Average {recall_weighted_key} across {N_SPLITS} folds: {avg_recall_weighted:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Individual Fold Metrics ---\")\n",
    "    for i, metrics_dict in enumerate(all_fold_metrics):\n",
    "        print(f\"Fold {i + 1}/{N_SPLITS}:\")\n",
    "        for metric_name, metric_value in metrics_dict.items():\n",
    "            # Only print metrics that are simple numerical values for cleaner output\n",
    "            if isinstance(metric_value, (int, float)):\n",
    "                print(f\"  {metric_name}: {metric_value:.4f}\")\n",
    "            else:\n",
    "                print(f\"  {metric_name}: {metric_value}\") # e.g. runtime, samples_per_second\n",
    "else:\n",
    "    print(\"No fold metrics were collected. Ensure your cross-validation loop ran and appended results to 'all_fold_metrics'.\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e8513f",
   "metadata": {},
   "source": [
    "## Training the Model on full training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e80e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Ling Ling Li\\AppData\\Local\\Temp\\ipykernel_14180\\452844565.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  final_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='975' max='975' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [975/975 8:00:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.050300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.918100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.875700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.803900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.737800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.721300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.568100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.535200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.396600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.357200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.358400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.287200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.293200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.313300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final model saved to ./final_sentiment_model\n"
     ]
    }
   ],
   "source": [
    "final_model = get_model().to(device)\n",
    "final_model_epochs = 5 \n",
    "\n",
    "final_training_Args = TrainingArguments(\n",
    "output_dir=final_model_output,\n",
    "num_train_epochs=final_model_epochs,\n",
    "learning_rate=LR,\n",
    "per_device_train_batch_size=batch_size,\n",
    "per_device_eval_batch_size=batch_size,\n",
    "warmup_steps=100,\n",
    "weight_decay=0.01,\n",
    "logging_steps=50,\n",
    "eval_strategy= \"no\",\n",
    "load_best_model_at_end=False,\n",
    "save_total_limit=1,\n",
    ")\n",
    "\n",
    "final_trainer = Trainer(\n",
    "    model = final_model,\n",
    "    args = final_training_Args,\n",
    "    train_dataset = review_train_dataset,\n",
    "    tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "final_trainer.train()\n",
    "final_trainer.save_model()\n",
    "print(f\"final model saved to {final_model_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6e8bb",
   "metadata": {},
   "source": [
    "## Using the Final Model on The Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff48a7",
   "metadata": {},
   "source": [
    "#### Tokenizing the test data and turning it into a HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_test_df_sentiment_Label = drug_test_df['sentiment_label']\n",
    "tokenized_test_Benefits = tokenize(drug_test_df['benefitsReview'])\n",
    "review_test_Dict = {\"input_ids\" : tokenized_test_Benefits['input_ids'], \"token_type_ids\": tokenized_test_Benefits['token_type_ids'],\"attention_mask\": tokenized_test_Benefits['attention_mask'], \"labels\": torch.tensor(drug_test_df_sentiment_Label)}\n",
    "review_test_dataset = Dataset.from_dict(review_train_Dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f6fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 4: Final Evaluation on Test Set & Error Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ling Ling Li\\AppData\\Local\\Temp\\ipykernel_14180\\567209123.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on the test set (review_test_dataset)...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Test Set Performance ---\n",
      "  accuracy: 0.9411\n",
      "  f1_weighted: 0.9405\n",
      "  precision_weighted: 0.9406\n",
      "  recall_weighted: 0.9411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Phase 4: Final Evaluation on Test Set & Error Analysis ---\")\n",
    "\n",
    "testing_the_final_model = AutoModelForSequenceClassification.from_pretrained(final_model_output).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(final_model_output)\n",
    "\n",
    "\n",
    "\n",
    "eval_output_dir_test = f\"{final_model_output}/test_evaluation_output\" \n",
    "test_eval_args = TrainingArguments(\n",
    "    output_dir=eval_output_dir_test,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "eval_trainer = Trainer(\n",
    "    model=testing_the_final_model, \n",
    "    args=test_eval_args,\n",
    "    compute_metrics=compute_classification_metrics, \n",
    "    tokenizer=tokenizer \n",
    ")\n",
    "\n",
    "print(\"Running evaluation on the test set (review_test_dataset)...\")\n",
    "\n",
    "prediction_output_test = eval_trainer.predict(review_test_dataset) \n",
    "\n",
    "logits_test = prediction_output_test.predictions\n",
    "true_ids_test = prediction_output_test.label_ids\n",
    "predicted_ids_test = np.argmax(logits_test, axis=-1)\n",
    "\n",
    "# Calculate overall metrics using the results from predict()\n",
    "eval_pred_obj_test = EvalPrediction(predictions=logits_test, label_ids=true_ids_test)\n",
    "final_test_set_metrics = compute_classification_metrics(eval_pred_obj_test)\n",
    "\n",
    "print(f\"\\n--- Final Test Set Performance ---\")\n",
    "for key, value in final_test_set_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a10b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
